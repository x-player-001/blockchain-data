#!/usr/bin/env python3
"""
å®šæ—¶ä»»åŠ¡å®ˆæŠ¤è¿›ç¨‹
è´Ÿè´£è¿è¡Œä¸¤ä¸ªå®šæ—¶ä»»åŠ¡ï¼š
1. æ¯10åˆ†é’Ÿçˆ¬å– DexScreener é¦–é¡µæ•°æ®ï¼ˆå¯é€‰ï¼‰
2. æ¯5åˆ†é’Ÿè¿è¡Œç›‘æ§æ›´æ–°ä»·æ ¼

ä½¿ç”¨æ–¹æ³•ï¼š
- å¯åŠ¨æ‰€æœ‰ä»»åŠ¡ï¼ˆçˆ¬è™«+ç›‘æ§ï¼‰ï¼špython scheduler_daemon.py
- åªå¯åŠ¨ç›‘æ§ä»»åŠ¡ï¼špython scheduler_daemon.py --monitor-only
- æŸ¥çœ‹å¸®åŠ©ï¼špython scheduler_daemon.py --help
"""

import asyncio
import logging
import signal
import sys
import random
import argparse
from datetime import datetime, timedelta
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.interval import IntervalTrigger
from apscheduler.triggers.date import DateTrigger

from src.services.token_monitor_service import TokenMonitorService
from src.services.multi_chain_scraper import MultiChainScraper

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/tmp/scheduler.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# å…¨å±€å˜é‡
scheduler = None
monitor_service = None
enable_scraper = True  # æ˜¯å¦å¯ç”¨çˆ¬è™«ä»»åŠ¡


async def scrape_dexscreener_task():
    """
    çˆ¬å– DexScreener é¦–é¡µä»»åŠ¡ï¼ˆéšæœºé—´éš”9-15åˆ†é’Ÿï¼‰
    ä½¿ç”¨ cloudscraper çˆ¬å– BSC å’Œ Solana é“¾
    æ”¯æŒé‡è¯•æœºåˆ¶æé«˜æˆåŠŸç‡
    """
    scraper = None
    monitor_service = None

    try:
        logger.info("="*80)
        logger.info("å¼€å§‹çˆ¬å– DexScreener é¦–é¡µï¼ˆå¤šé“¾ï¼‰...")
        logger.info("="*80)

        # ä½¿ç”¨æ–°çš„å¤šé“¾çˆ¬è™«
        scraper = MultiChainScraper()

        # çˆ¬å–å¹¶ä¿å­˜åˆ° potential_tokens è¡¨
        result = await scraper.scrape_and_save_multi_chain(
            chains=['bsc', 'solana'],  # çˆ¬å– BSC å’Œ Solana é“¾
            count_per_chain=100,       # æ¯æ¡é“¾çˆ¬å–100ä¸ªä»£å¸
            top_n_per_chain=10         # æ¯æ¡é“¾å–å‰10åæ¶¨å¹…æ¦œ
        )

        logger.info(
            f"çˆ¬å–å®Œæˆï¼šæ€»å…±ä¿å­˜ {result['total_saved']} ä¸ªä»£å¸åˆ°æ•°æ®åº“ï¼Œ"
            f"è·³è¿‡ {result['total_skipped']} ä¸ª"
        )
        logger.info("="*80)

        # çˆ¬å–å®Œæˆåï¼Œç«‹å³æ›´æ–°æ½œåŠ›ä»£å¸çš„ AVE API æ•°æ®
        if result['total_saved'] > 0:
            logger.info("\n" + "="*80)
            logger.info("æ›´æ–°æ½œåŠ›ä»£å¸çš„ AVE API æ•°æ®...")
            logger.info("="*80)

            monitor_service = TokenMonitorService()
            update_result = await monitor_service.update_potential_tokens_data(
                delay=0.3,
                min_update_interval_minutes=0  # çˆ¬å–åç«‹å³æ›´æ–°ï¼Œä¸æ£€æŸ¥é—´éš”
            )

            logger.info(
                f"æ›´æ–°å®Œæˆï¼šæˆåŠŸ {update_result.get('updated', 0)} ä¸ªï¼Œ"
                f"å¤±è´¥ {update_result.get('failed', 0)} ä¸ª"
            )
            logger.info("="*80)

        # è°ƒåº¦ä¸‹ä¸€æ¬¡çˆ¬å–ä»»åŠ¡ï¼ˆéšæœºé—´éš”9-15åˆ†é’Ÿï¼‰
        schedule_next_scrape()

    except Exception as e:
        logger.error(f"çˆ¬å–ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        # å³ä½¿å¤±è´¥ä¹Ÿè¦è°ƒåº¦ä¸‹ä¸€æ¬¡
        schedule_next_scrape()

    finally:
        # å…³é—­è¿æ¥
        if scraper:
            await scraper.close()
        if monitor_service:
            await monitor_service.close()


def schedule_next_scrape():
    """
    è°ƒåº¦ä¸‹ä¸€æ¬¡çˆ¬å–ä»»åŠ¡ï¼ˆéšæœºé—´éš”9-15åˆ†é’Ÿï¼‰
    """
    global scheduler, enable_scraper

    # å¦‚æœçˆ¬è™«è¢«ç¦ç”¨ï¼Œä¸è°ƒåº¦
    if not enable_scraper:
        return

    if scheduler:
        # è®¡ç®—éšæœºé—´éš”æ—¶é—´ï¼ˆ9-15åˆ†é’Ÿï¼‰
        next_run_minutes = random.uniform(9, 15)
        next_run_time = datetime.now() + timedelta(minutes=next_run_minutes)

        # ç§»é™¤æ—§çš„çˆ¬å–ä»»åŠ¡
        try:
            scheduler.remove_job('scrape_dexscreener')
        except:
            pass

        # æ·»åŠ æ–°çš„ä¸€æ¬¡æ€§ä»»åŠ¡
        scheduler.add_job(
            scrape_dexscreener_task,
            trigger=DateTrigger(run_date=next_run_time),
            id='scrape_dexscreener',
            name='çˆ¬å–DexScreeneré¦–é¡µ',
            max_instances=1,
            coalesce=True,
            misfire_grace_time=60
        )

        logger.info(f"ğŸ“… ä¸‹æ¬¡çˆ¬å–æ—¶é—´: {next_run_time.strftime('%Y-%m-%d %H:%M:%S')} "
                   f"(é—´éš” {next_run_minutes:.1f} åˆ†é’Ÿ)")



async def monitor_prices_task():
    """
    ç›‘æ§ä»·æ ¼ä»»åŠ¡ï¼ˆæ¯5åˆ†é’Ÿï¼‰
    æ›´æ–°ç›‘æ§ä»£å¸ä»·æ ¼ + æ½œåŠ›ä»£å¸æ•°æ®
    """
    global monitor_service

    try:
        logger.info("="*80)
        logger.info("å¼€å§‹æ›´æ–°ç›‘æ§ä»£å¸ä»·æ ¼...")
        logger.info("="*80)

        if not monitor_service:
            monitor_service = TokenMonitorService()

        # æ›´æ–°æ‰€æœ‰ç›‘æ§ä»£å¸çš„ä»·æ ¼
        result = await monitor_service.update_monitored_prices()

        logger.info(
            f"ä»·æ ¼æ›´æ–°å®Œæˆï¼šæ›´æ–° {result['updated']} ä¸ªä»£å¸ï¼Œ"
            f"è§¦å‘ {result['alerts_triggered']} ä¸ªæŠ¥è­¦"
        )
        logger.info("="*80)

        # åŒæ—¶æ›´æ–°æ½œåŠ›ä»£å¸çš„ AVE API æ•°æ®ï¼ˆå¸¦å»é‡æ£€æŸ¥ï¼‰
        logger.info("\n" + "="*80)
        logger.info("æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°æ½œåŠ›ä»£å¸æ•°æ®...")
        logger.info("="*80)

        potential_result = await monitor_service.update_potential_tokens_data(
            delay=0.3,
            min_update_interval_minutes=3  # æœ€å°‘é—´éš”3åˆ†é’Ÿï¼Œé¿å…é‡å¤è°ƒç”¨
        )

        if potential_result.get('skipped'):
            logger.info("æ½œåŠ›ä»£å¸æ•°æ®æ›´æ–°å·²è·³è¿‡ï¼ˆè·ä¸Šæ¬¡æ›´æ–°æ—¶é—´å¤ªçŸ­ï¼‰")
        else:
            logger.info(
                f"æ½œåŠ›ä»£å¸æ›´æ–°å®Œæˆï¼šæˆåŠŸ {potential_result.get('updated', 0)} ä¸ªï¼Œ"
                f"å¤±è´¥ {potential_result.get('failed', 0)} ä¸ª"
            )
        logger.info("="*80)

    except Exception as e:
        logger.error(f"ç›‘æ§ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)


def shutdown_handler(signum, frame):
    """
    ä¼˜é›…å…³é—­å¤„ç†
    """
    logger.info("æ”¶åˆ°å…³é—­ä¿¡å·ï¼Œæ­£åœ¨å…³é—­è°ƒåº¦å™¨...")

    if scheduler:
        scheduler.shutdown(wait=True)

    if monitor_service:
        asyncio.create_task(monitor_service.close())

    logger.info("è°ƒåº¦å™¨å·²å…³é—­")
    sys.exit(0)


async def main():
    """
    ä¸»å‡½æ•°ï¼šå¯åŠ¨è°ƒåº¦å™¨
    """
    global scheduler, monitor_service, enable_scraper

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(
        description='å®šæ—¶ä»»åŠ¡å®ˆæŠ¤è¿›ç¨‹ï¼šç›‘æ§ä»£å¸ä»·æ ¼å’Œçˆ¬å– DexScreener æ•°æ®',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•ï¼š
  python scheduler_daemon.py                   # å¯åŠ¨æ‰€æœ‰ä»»åŠ¡ï¼ˆçˆ¬è™«+ç›‘æ§ï¼‰
  python scheduler_daemon.py --monitor-only    # åªå¯åŠ¨ç›‘æ§ä»»åŠ¡ï¼ˆä¸çˆ¬å–ï¼‰
  python scheduler_daemon.py --scraper-only    # åªå¯åŠ¨çˆ¬è™«ä»»åŠ¡ï¼ˆä¸ç›‘æ§ï¼‰
        """
    )
    parser.add_argument(
        '--monitor-only',
        action='store_true',
        help='åªå¯åŠ¨ç›‘æ§ä»·æ ¼ä»»åŠ¡ï¼Œä¸å¯åŠ¨çˆ¬è™«'
    )
    parser.add_argument(
        '--scraper-only',
        action='store_true',
        help='åªå¯åŠ¨çˆ¬è™«ä»»åŠ¡ï¼Œä¸å¯åŠ¨ç›‘æ§'
    )

    args = parser.parse_args()

    # æ£€æŸ¥å‚æ•°å†²çª
    if args.monitor_only and args.scraper_only:
        logger.error("é”™è¯¯: --monitor-only å’Œ --scraper-only ä¸èƒ½åŒæ—¶ä½¿ç”¨")
        sys.exit(1)

    # ç¡®å®šå¯ç”¨å“ªäº›ä»»åŠ¡
    enable_scraper = not args.monitor_only
    enable_monitor = not args.scraper_only

    logger.info("="*80)
    logger.info("å®šæ—¶ä»»åŠ¡å®ˆæŠ¤è¿›ç¨‹å¯åŠ¨")
    logger.info("="*80)

    # æ³¨å†Œä¿¡å·å¤„ç†
    signal.signal(signal.SIGINT, shutdown_handler)
    signal.signal(signal.SIGTERM, shutdown_handler)

    # åˆå§‹åŒ–æœåŠ¡
    monitor_service = TokenMonitorService()

    # åˆ›å»ºè°ƒåº¦å™¨
    scheduler = AsyncIOScheduler(timezone='UTC')

    # æ ¹æ®å‚æ•°æ·»åŠ ä»»åŠ¡
    if enable_monitor:
        scheduler.add_job(
            monitor_prices_task,
            trigger=IntervalTrigger(minutes=5),
            id='monitor_prices',
            name='ç›‘æ§ä»£å¸ä»·æ ¼',
            max_instances=1,
            coalesce=True,
            misfire_grace_time=30
        )
        logger.info("âœ… å·²å¯ç”¨ä»»åŠ¡ï¼šæ¯5åˆ†é’Ÿç›‘æ§ä»£å¸ä»·æ ¼")

    # å¯åŠ¨è°ƒåº¦å™¨
    scheduler.start()

    logger.info("è°ƒåº¦å™¨å·²å¯åŠ¨ï¼Œä»»åŠ¡è®¡åˆ’ï¼š")
    if enable_scraper:
        logger.info("  - éšæœºé—´éš”9-15åˆ†é’Ÿçˆ¬å– DexScreener é¦–é¡µï¼ˆBSC + Solanaï¼Œæ”¯æŒé‡è¯•æœºåˆ¶ï¼‰")
    if enable_monitor:
        logger.info("  - æ¯5åˆ†é’Ÿç›‘æ§ä»£å¸ä»·æ ¼ï¼ˆæ›´æ–° monitored_tokens è¡¨å¹¶è§¦å‘æŠ¥è­¦ + æ›´æ–° potential_tokens AVE æ•°æ®ï¼‰")
    logger.info("="*80)

    # å¯åŠ¨æ—¶ç«‹å³æ‰§è¡Œä¸€æ¬¡ä»»åŠ¡
    if enable_scraper:
        logger.info("ç«‹å³æ‰§è¡Œä¸€æ¬¡çˆ¬å–ä»»åŠ¡...")
        await scrape_dexscreener_task()

    if enable_monitor:
        logger.info("ç«‹å³æ‰§è¡Œä¸€æ¬¡ç›‘æ§ä»»åŠ¡...")
        await monitor_prices_task()

    # ä¿æŒè¿è¡Œ
    try:
        while True:
            await asyncio.sleep(60)
    except (KeyboardInterrupt, SystemExit):
        logger.info("æ¥æ”¶åˆ°é€€å‡ºä¿¡å·")
    finally:
        if scheduler:
            scheduler.shutdown(wait=True)
        if monitor_service:
            await monitor_service.close()
        logger.info("å®šæ—¶ä»»åŠ¡å®ˆæŠ¤è¿›ç¨‹å·²å…³é—­")


if __name__ == "__main__":
    asyncio.run(main())

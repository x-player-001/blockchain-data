#!/usr/bin/env python3
"""
å®šæ—¶ä»»åŠ¡å®ˆæŠ¤è¿›ç¨‹
è´Ÿè´£è¿è¡Œä¸¤ä¸ªå®šæ—¶ä»»åŠ¡ï¼š
1. æ¯10åˆ†é’Ÿçˆ¬å– DexScreener é¦–é¡µæ•°æ®ï¼ˆå¯é€‰ï¼‰
2. æ¯5åˆ†é’Ÿè¿è¡Œç›‘æ§æ›´æ–°ä»·æ ¼

ä½¿ç”¨æ–¹æ³•ï¼š
- å¯åŠ¨æ‰€æœ‰ä»»åŠ¡ï¼ˆçˆ¬è™«+ç›‘æ§ï¼‰ï¼špython scheduler_daemon.py
- åªå¯åŠ¨ç›‘æ§ä»»åŠ¡ï¼špython scheduler_daemon.py --monitor-only
- æŸ¥çœ‹å¸®åŠ©ï¼špython scheduler_daemon.py --help
"""

import asyncio
import logging
import signal
import sys
import os
import random
import argparse
from datetime import datetime, timedelta
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.interval import IntervalTrigger
from apscheduler.triggers.date import DateTrigger

from src.services.token_monitor_service import TokenMonitorService
from src.services.multi_chain_scraper import MultiChainScraper

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/tmp/scheduler.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# å…¨å±€å˜é‡
scheduler = None
monitor_service = None
enable_scraper = True  # æ˜¯å¦å¯ç”¨çˆ¬è™«ä»»åŠ¡
use_undetected_chrome = os.getenv('USE_UNDETECTED_CHROME', 'false').lower() == 'true'


async def scrape_dexscreener_task():
    """
    çˆ¬å– DexScreener é¦–é¡µä»»åŠ¡ï¼ˆä»æ•°æ®åº“è¯»å–é…ç½®ï¼‰
    ä½¿ç”¨ cloudscraper æˆ– undetected-chromedriver çˆ¬å–å¤šé“¾æ•°æ®
    æ”¯æŒé‡è¯•æœºåˆ¶æé«˜æˆåŠŸç‡
    """
    scraper = None
    monitor_service = None

    try:
        logger.info("="*80)
        logger.info("å¼€å§‹çˆ¬å– DexScreener é¦–é¡µï¼ˆå¤šé“¾ï¼‰...")
        logger.info("="*80)

        # 1. ä»æ•°æ®åº“è¯»å–é…ç½®
        monitor_service = TokenMonitorService()
        config = await monitor_service.get_scraper_config()

        if not config:
            logger.error("æœªæ‰¾åˆ°çˆ¬è™«é…ç½®ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            config = {
                'enabled_chains': ['bsc', 'solana'],
                'count_per_chain': 100,
                'top_n_per_chain': 10,
                'use_undetected_chrome': use_undetected_chrome,
                'enabled': True,
                'scrape_interval_min': 9,
                'scrape_interval_max': 15
            }

        # 2. æ£€æŸ¥é…ç½®æ˜¯å¦å¯ç”¨
        if not config.get('enabled', True):
            logger.info("çˆ¬è™«é…ç½®å·²ç¦ç”¨ï¼Œè·³è¿‡æœ¬æ¬¡çˆ¬å–")
            schedule_next_scrape(config)
            return

        logger.info(f"é…ç½®ä¿¡æ¯: chains={config['enabled_chains']}, "
                   f"count_per_chain={config['count_per_chain']}, "
                   f"top_n_per_chain={config['top_n_per_chain']}, "
                   f"use_undetected_chrome={config['use_undetected_chrome']}")

        # 3. ä½¿ç”¨é…ç½®å‚æ•°çˆ¬å–
        scraper = MultiChainScraper()

        # çˆ¬å–å¹¶ä¿å­˜åˆ° potential_tokens è¡¨
        result = await scraper.scrape_and_save_multi_chain(
            chains=config['enabled_chains'],              # ä»é…ç½®è¯»å–é“¾åˆ—è¡¨
            count_per_chain=config['count_per_chain'],    # ä»é…ç½®è¯»å–æ¯æ¡é“¾çˆ¬å–æ€»æ•°
            top_n_per_chain=config['top_n_per_chain'],    # ä»é…ç½®è¯»å–æ¯æ¡é“¾å–å‰Nå
            use_undetected_chrome=config['use_undetected_chrome']  # ä»é…ç½®è¯»å–çˆ¬å–æ–¹æ³•
        )

        logger.info(
            f"çˆ¬å–å®Œæˆï¼šæ€»å…±ä¿å­˜ {result['total_saved']} ä¸ªä»£å¸åˆ°æ•°æ®åº“ï¼Œ"
            f"è·³è¿‡ {result['total_skipped']} ä¸ª"
        )
        logger.info("="*80)

        # çˆ¬å–å®Œæˆåï¼Œç«‹å³æ›´æ–°æ½œåŠ›ä»£å¸çš„ AVE API æ•°æ®
        if result['total_saved'] > 0:
            logger.info("\n" + "="*80)
            logger.info("æ›´æ–°æ½œåŠ›ä»£å¸çš„ AVE API æ•°æ®...")
            logger.info("="*80)

            if not monitor_service:
                monitor_service = TokenMonitorService()

            update_result = await monitor_service.update_potential_tokens_data(
                delay=0.3,
                min_update_interval_minutes=0  # çˆ¬å–åç«‹å³æ›´æ–°ï¼Œä¸æ£€æŸ¥é—´éš”
            )

            logger.info(
                f"æ›´æ–°å®Œæˆï¼šæˆåŠŸ {update_result.get('updated', 0)} ä¸ªï¼Œ"
                f"å¤±è´¥ {update_result.get('failed', 0)} ä¸ª"
            )
            logger.info("="*80)

        # è°ƒåº¦ä¸‹ä¸€æ¬¡çˆ¬å–ä»»åŠ¡ï¼ˆä½¿ç”¨é…ç½®çš„é—´éš”æ—¶é—´ï¼‰
        schedule_next_scrape(config)

    except Exception as e:
        logger.error(f"çˆ¬å–ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        # å³ä½¿å¤±è´¥ä¹Ÿè¦è°ƒåº¦ä¸‹ä¸€æ¬¡ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
        schedule_next_scrape()

    finally:
        # å…³é—­è¿æ¥
        if scraper:
            await scraper.close()
        if monitor_service:
            await monitor_service.close()


def schedule_next_scrape(config=None):
    """
    è°ƒåº¦ä¸‹ä¸€æ¬¡çˆ¬å–ä»»åŠ¡ï¼ˆä½¿ç”¨é…ç½®çš„é—´éš”æ—¶é—´æˆ–é»˜è®¤9-15åˆ†é’Ÿï¼‰

    Args:
        config: çˆ¬è™«é…ç½®å­—å…¸ï¼ŒåŒ…å« scrape_interval_min å’Œ scrape_interval_max
    """
    global scheduler, enable_scraper

    # å¦‚æœçˆ¬è™«è¢«ç¦ç”¨ï¼Œä¸è°ƒåº¦
    if not enable_scraper:
        return

    if scheduler:
        # ä»é…ç½®è¯»å–é—´éš”æ—¶é—´ï¼Œå¦‚æœæ²¡æœ‰é…ç½®åˆ™ä½¿ç”¨é»˜è®¤å€¼ï¼ˆ9-15åˆ†é’Ÿï¼‰
        if config:
            interval_min = config.get('scrape_interval_min', 9)
            interval_max = config.get('scrape_interval_max', 15)
        else:
            interval_min = 9
            interval_max = 15

        # è®¡ç®—éšæœºé—´éš”æ—¶é—´
        next_run_minutes = random.uniform(interval_min, interval_max)
        next_run_time = datetime.now() + timedelta(minutes=next_run_minutes)

        # ç§»é™¤æ—§çš„çˆ¬å–ä»»åŠ¡
        try:
            scheduler.remove_job('scrape_dexscreener')
        except:
            pass

        # æ·»åŠ æ–°çš„ä¸€æ¬¡æ€§ä»»åŠ¡
        scheduler.add_job(
            scrape_dexscreener_task,
            trigger=DateTrigger(run_date=next_run_time),
            id='scrape_dexscreener',
            name='çˆ¬å–DexScreeneré¦–é¡µ',
            max_instances=1,
            coalesce=True,
            misfire_grace_time=60
        )

        logger.info(f"ğŸ“… ä¸‹æ¬¡çˆ¬å–æ—¶é—´: {next_run_time.strftime('%Y-%m-%d %H:%M:%S')} "
                   f"(é—´éš” {next_run_minutes:.1f} åˆ†é’Ÿ)")



async def monitor_prices_task():
    """
    ç›‘æ§ä»·æ ¼ä»»åŠ¡ï¼ˆæ¯5åˆ†é’Ÿï¼‰
    æ›´æ–°ç›‘æ§ä»£å¸ä»·æ ¼ + æ½œåŠ›ä»£å¸æ•°æ®
    """
    global monitor_service

    try:
        logger.info("="*80)
        logger.info("å¼€å§‹æ›´æ–°ç›‘æ§ä»£å¸ä»·æ ¼...")
        logger.info("="*80)

        if not monitor_service:
            monitor_service = TokenMonitorService()

        # æ›´æ–°æ‰€æœ‰ç›‘æ§ä»£å¸çš„ä»·æ ¼
        result = await monitor_service.update_monitored_prices()

        logger.info(
            f"ä»·æ ¼æ›´æ–°å®Œæˆï¼šæ›´æ–° {result['updated']} ä¸ªä»£å¸ï¼Œ"
            f"è§¦å‘ {result['alerts_triggered']} ä¸ªæŠ¥è­¦"
        )
        logger.info("="*80)

        # åŒæ—¶æ›´æ–°æ½œåŠ›ä»£å¸çš„ AVE API æ•°æ®ï¼ˆå¸¦å»é‡æ£€æŸ¥ï¼‰
        logger.info("\n" + "="*80)
        logger.info("æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°æ½œåŠ›ä»£å¸æ•°æ®...")
        logger.info("="*80)

        potential_result = await monitor_service.update_potential_tokens_data(
            delay=0.3,
            min_update_interval_minutes=3  # æœ€å°‘é—´éš”3åˆ†é’Ÿï¼Œé¿å…é‡å¤è°ƒç”¨
        )

        if potential_result.get('skipped'):
            logger.info("æ½œåŠ›ä»£å¸æ•°æ®æ›´æ–°å·²è·³è¿‡ï¼ˆè·ä¸Šæ¬¡æ›´æ–°æ—¶é—´å¤ªçŸ­ï¼‰")
        else:
            logger.info(
                f"æ½œåŠ›ä»£å¸æ›´æ–°å®Œæˆï¼šæˆåŠŸ {potential_result.get('updated', 0)} ä¸ªï¼Œ"
                f"å¤±è´¥ {potential_result.get('failed', 0)} ä¸ª"
            )
        logger.info("="*80)

    except Exception as e:
        logger.error(f"ç›‘æ§ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)


def shutdown_handler(signum, frame):
    """
    ä¼˜é›…å…³é—­å¤„ç†
    """
    global scheduler
    logger.info("æ”¶åˆ°å…³é—­ä¿¡å·ï¼Œæ­£åœ¨å…³é—­è°ƒåº¦å™¨...")

    if scheduler:
        try:
            scheduler.shutdown(wait=False)
            logger.info("è°ƒåº¦å™¨å·²å…³é—­")
        except Exception:
            pass  # å¿½ç•¥é‡å¤å…³é—­çš„é”™è¯¯

    # ç›´æ¥é€€å‡ºï¼ˆé¿å…ç¨‹åºå¡æ­»ï¼‰
    import os
    os._exit(0)


async def main():
    """
    ä¸»å‡½æ•°ï¼šå¯åŠ¨è°ƒåº¦å™¨
    """
    global scheduler, monitor_service, enable_scraper

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(
        description='å®šæ—¶ä»»åŠ¡å®ˆæŠ¤è¿›ç¨‹ï¼šç›‘æ§ä»£å¸ä»·æ ¼å’Œçˆ¬å– DexScreener æ•°æ®',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•ï¼š
  python scheduler_daemon.py                   # å¯åŠ¨æ‰€æœ‰ä»»åŠ¡ï¼ˆçˆ¬è™«+ç›‘æ§ï¼‰
  python scheduler_daemon.py --monitor-only    # åªå¯åŠ¨ç›‘æ§ä»»åŠ¡ï¼ˆä¸çˆ¬å–ï¼‰
  python scheduler_daemon.py --scraper-only    # åªå¯åŠ¨çˆ¬è™«ä»»åŠ¡ï¼ˆä¸ç›‘æ§ï¼‰
        """
    )
    parser.add_argument(
        '--monitor-only',
        action='store_true',
        help='åªå¯åŠ¨ç›‘æ§ä»·æ ¼ä»»åŠ¡ï¼Œä¸å¯åŠ¨çˆ¬è™«'
    )
    parser.add_argument(
        '--scraper-only',
        action='store_true',
        help='åªå¯åŠ¨çˆ¬è™«ä»»åŠ¡ï¼Œä¸å¯åŠ¨ç›‘æ§'
    )
    parser.add_argument(
        '--use-undetected-chrome',
        action='store_true',
        help='ä½¿ç”¨ undetected-chromedriver çˆ¬å–ï¼ˆæˆåŠŸç‡æ›´é«˜ï¼Œéœ€è¦å®‰è£… Chromeï¼‰'
    )

    args = parser.parse_args()

    # æ£€æŸ¥å‚æ•°å†²çª
    if args.monitor_only and args.scraper_only:
        logger.error("é”™è¯¯: --monitor-only å’Œ --scraper-only ä¸èƒ½åŒæ—¶ä½¿ç”¨")
        sys.exit(1)

    # ç¡®å®šå¯ç”¨å“ªäº›ä»»åŠ¡
    enable_scraper = not args.monitor_only
    enable_monitor = not args.scraper_only

    # è®¾ç½®çˆ¬å–æ–¹æ³•
    global use_undetected_chrome
    if args.use_undetected_chrome:
        use_undetected_chrome = True

    logger.info("="*80)
    logger.info("å®šæ—¶ä»»åŠ¡å®ˆæŠ¤è¿›ç¨‹å¯åŠ¨")
    if use_undetected_chrome:
        logger.info("çˆ¬å–æ–¹æ³•: undetected-chromedriverï¼ˆé«˜æˆåŠŸç‡æ¨¡å¼ï¼‰")
    else:
        logger.info("çˆ¬å–æ–¹æ³•: cloudscraperï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰")
    logger.info("="*80)

    # æ³¨å†Œä¿¡å·å¤„ç†
    signal.signal(signal.SIGINT, shutdown_handler)
    signal.signal(signal.SIGTERM, shutdown_handler)

    # åˆå§‹åŒ–æœåŠ¡
    monitor_service = TokenMonitorService()

    # åˆ›å»ºè°ƒåº¦å™¨
    scheduler = AsyncIOScheduler(timezone='UTC')

    # æ ¹æ®å‚æ•°æ·»åŠ ä»»åŠ¡
    if enable_monitor:
        scheduler.add_job(
            monitor_prices_task,
            trigger=IntervalTrigger(minutes=5),
            id='monitor_prices',
            name='ç›‘æ§ä»£å¸ä»·æ ¼',
            max_instances=1,
            coalesce=True,
            misfire_grace_time=30
        )
        logger.info("âœ… å·²å¯ç”¨ä»»åŠ¡ï¼šæ¯5åˆ†é’Ÿç›‘æ§ä»£å¸ä»·æ ¼")

    # å¯åŠ¨è°ƒåº¦å™¨
    scheduler.start()

    logger.info("è°ƒåº¦å™¨å·²å¯åŠ¨ï¼Œä»»åŠ¡è®¡åˆ’ï¼š")
    if enable_scraper:
        logger.info("  - éšæœºé—´éš”9-15åˆ†é’Ÿçˆ¬å– DexScreener é¦–é¡µï¼ˆBSC + Solanaï¼Œæ”¯æŒé‡è¯•æœºåˆ¶ï¼‰")
    if enable_monitor:
        logger.info("  - æ¯5åˆ†é’Ÿç›‘æ§ä»£å¸ä»·æ ¼ï¼ˆæ›´æ–° monitored_tokens è¡¨å¹¶è§¦å‘æŠ¥è­¦ + æ›´æ–° potential_tokens AVE æ•°æ®ï¼‰")
    logger.info("="*80)

    # å¯åŠ¨æ—¶ç«‹å³æ‰§è¡Œä¸€æ¬¡ä»»åŠ¡
    if enable_scraper:
        logger.info("ç«‹å³æ‰§è¡Œä¸€æ¬¡çˆ¬å–ä»»åŠ¡...")
        await scrape_dexscreener_task()

    if enable_monitor:
        logger.info("ç«‹å³æ‰§è¡Œä¸€æ¬¡ç›‘æ§ä»»åŠ¡...")
        await monitor_prices_task()

    # ä¿æŒè¿è¡Œ
    try:
        while True:
            await asyncio.sleep(60)
    except (KeyboardInterrupt, SystemExit):
        logger.info("æ¥æ”¶åˆ°é€€å‡ºä¿¡å·")
    except Exception as e:
        logger.error(f"è¿è¡Œæ—¶é”™è¯¯: {e}", exc_info=True)
    finally:
        logger.info("æ­£åœ¨å…³é—­æœåŠ¡...")
        if scheduler:
            try:
                scheduler.shutdown(wait=False)
            except:
                pass
        if monitor_service:
            try:
                await monitor_service.close()
            except:
                pass
        logger.info("âœ… å®šæ—¶ä»»åŠ¡å®ˆæŠ¤è¿›ç¨‹å·²å®‰å…¨å…³é—­")


if __name__ == "__main__":
    asyncio.run(main())

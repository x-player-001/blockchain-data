#!/usr/bin/env python3
"""
DexScreener çˆ¬è™« - æœ€ç»ˆç‰ˆæœ¬
æ”¯æŒ BSC å’Œ Solana é“¾
æŒ‰ 24h æ¶¨å¹…æ’åºå–å‰10
"""

import cloudscraper
from bs4 import BeautifulSoup
from typing import List, Dict, Any
from datetime import datetime
import json
import time


def parse_value_with_unit(text: str) -> float:
    """è§£æå¸¦å•ä½çš„æ•°å€¼ (K, M, B)"""
    if not text or text == '--':
        return 0.0
    text = text.strip().replace(',', '').replace('$', '')
    multipliers = {'K': 1_000, 'M': 1_000_000, 'B': 1_000_000_000}
    for suffix, multiplier in multipliers.items():
        if suffix in text:
            try:
                return float(text.replace(suffix, '')) * multiplier
            except:
                return 0.0
    try:
        return float(text)
    except:
        return 0.0


def parse_token_row(row_element, rank: int, chain: str) -> Dict[str, Any]:
    """è§£æå•ä¸ªä»£å¸è¡Œ"""
    href = row_element.get('href', '')
    chain_prefix = f'/{chain}/'

    if chain_prefix not in href:
        return None

    pair_address = href.split(chain_prefix)[-1].split('?')[0]

    # BSCæ˜¯42ä½ï¼ŒSolanaæ˜¯44ä½
    expected_len = 42 if chain == 'bsc' else 44
    if len(pair_address) != expected_len:
        return None

    full_text = row_element.get_text(separator='|', strip=True)
    parts = full_text.split('|')

    token_data = {
        'pair_address': pair_address,
        'url': f"https://dexscreener.com{href}",
        'rank': rank,
        'chain': chain,
    }

    try:
        # æå–åŸºæœ¬ä¿¡æ¯ (BSC å’Œ Solana ç»“æ„ä¸åŒ)
        if chain == 'bsc':
            # BSC: parts[3]=åç§°, parts[5]=WBNB, parts[6]=ç¬¦å·
            if len(parts) > 6:
                token_data['token_name'] = parts[3]
                token_data['base_token'] = parts[5]
                token_data['token_symbol'] = parts[6]
        else:  # solana
            # Solana æœ‰å¤šç§æ ¼å¼ï¼Œéœ€è¦æ£€æµ‹ DEX ç±»å‹æ ‡è®°
            # æ ‡å‡†: #|rank|symbol|/|SOL|name|...
            # CPMM: #|rank|CPMM|symbol|/|SOL|name|...
            # DLMM: #|rank|DLMM|symbol|/|SOL|name|...

            dex_types = ['CPMM', 'CLMM', 'DLMM', 'DYN', 'DYN2', 'wp', 'v2', 'v3']
            offset = 0

            # æ£€æŸ¥ parts[2] æ˜¯å¦æ˜¯ DEX ç±»å‹æ ‡è®°
            if len(parts) > 2 and parts[2] in dex_types:
                offset = 1  # å­—æ®µä½ç½®åç§»1ä½
                token_data['dex_type'] = parts[2]

            # æ ¹æ®åç§»æå–å­—æ®µ
            symbol_idx = 2 + offset
            base_idx = 4 + offset
            name_idx = 5 + offset

            if len(parts) > name_idx:
                token_data['token_symbol'] = parts[symbol_idx]
                token_data['base_token'] = parts[base_idx]
                token_data['token_name'] = parts[name_idx]

        # æå–ä»·æ ¼ï¼ˆå¤„ç†ç‰¹æ®Šæ ¼å¼ï¼š0.0|é›¶çš„ä¸ªæ•°|æœ‰æ•ˆæ•°å­—ï¼‰
        for i, part in enumerate(parts):
            if part == '$' and i + 1 < len(parts):
                try:
                    first = parts[i + 1]

                    # æ£€æŸ¥æ˜¯å¦æ˜¯ç‰¹æ®Šæ ¼å¼ï¼š0.0|4|9152 = 0.00009152
                    if (first == '0.0' and i + 3 < len(parts) and
                        parts[i + 2].isdigit() and parts[i + 3].isdigit()):
                        zero_count = int(parts[i + 2])
                        significant = parts[i + 3]
                        price_str = '0.' + ('0' * zero_count) + significant
                        token_data['price_usd'] = float(price_str)
                        break

                    # æ™®é€šæ ¼å¼
                    if 'K' not in first and 'M' not in first and 'B' not in first:
                        token_data['price_usd'] = float(first)
                        break
                except:
                    pass

        # æå–ç™¾åˆ†æ¯” (5m, 1h, 6h, 24h)
        # å…³é”®ï¼šå»é™¤é€—å·ï¼
        percent_positions = []
        for i, part in enumerate(parts):
            if '%' in part and part != '%':
                try:
                    value = float(part.replace('%', '').replace('+', '').replace(',', ''))
                    percent_positions.append((i, value))
                except:
                    pass

        # æ‰¾è¿ç»­çš„4ä¸ªç™¾åˆ†æ¯”
        if len(percent_positions) >= 4:
            for i in range(len(percent_positions) - 3):
                pos1, val1 = percent_positions[i]
                pos2, val2 = percent_positions[i + 1]
                pos3, val3 = percent_positions[i + 2]
                pos4, val4 = percent_positions[i + 3]

                if (pos2 - pos1 <= 2 and pos3 - pos2 <= 2 and pos4 - pos3 <= 2):
                    token_data['price_change_5m'] = val1
                    token_data['price_change_1h'] = val2
                    token_data['price_change_6h'] = val3
                    token_data['price_change_24h'] = val4
                    break

        # æå–å¸‚å€¼ã€æµåŠ¨æ€§ã€FDV
        dollar_values = []
        for i, part in enumerate(parts):
            if part == '$' and i + 1 < len(parts):
                next_part = parts[i + 1]
                if any(unit in next_part for unit in ['K', 'M', 'B']):
                    dollar_values.append(parse_value_with_unit(next_part))

        if len(dollar_values) >= 1:
            token_data['market_cap'] = dollar_values[0]
        if len(dollar_values) >= 2:
            token_data['liquidity_usd'] = dollar_values[1]
        if len(dollar_values) >= 3:
            token_data['fdv'] = dollar_values[2]

        # æå–äº¤æ˜“é‡
        for part in parts[10:15]:
            if ',' in part and '$' not in part:
                try:
                    token_data['volume_24h'] = float(part.replace(',', ''))
                    break
                except:
                    pass

    except Exception as e:
        pass

    return token_data


def scrape_dexscreener(chain: str = 'bsc', limit: int = 100, verbose: bool = True) -> List[Dict[str, Any]]:
    """
    çˆ¬å– DexScreener

    Args:
        chain: bsc æˆ– solana
        limit: æœ€å¤šè·å–å¤šå°‘ä¸ªä»£å¸
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
    """
    if verbose:
        print(f"\n{'='*80}")
        print(f"çˆ¬å– DexScreener {chain.upper()} é“¾")
        print(f"{'='*80}\n")

    scraper = cloudscraper.create_scraper(
        browser={'browser': 'chrome', 'platform': 'darwin', 'mobile': False, 'desktop': True},
        delay=10,
    )

    headers = {
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Accept-Encoding': 'gzip, deflate, br',
        'DNT': '1',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none',
        'Sec-Fetch-User': '?1',
    }

    url = f"https://dexscreener.com/{chain}"

    if verbose:
        print(f"1. è¯·æ±‚é¡µé¢: {url}")

    try:
        response = scraper.get(url, headers=headers, timeout=30)
    except Exception as e:
        if verbose:
            print(f"   âŒ è¯·æ±‚å¤±è´¥: {e}")
        return []

    if response.status_code != 200:
        if verbose:
            print(f"   âŒ çŠ¶æ€ç : {response.status_code}")
            print(f"   æç¤º: Cloudflare å¯èƒ½æš‚æ—¶æ‹¦æˆªï¼Œè¯·ç­‰å¾…å‡ åˆ†é’Ÿåé‡è¯•")
        return []

    if 'è¯·ç¨å€™' in response.text or 'Just a moment' in response.text:
        if verbose:
            print("   âŒ è¢« Cloudflare æ‹¦æˆª")
        return []

    if verbose:
        print(f"   âœ“ çŠ¶æ€ç : {response.status_code}")
        print(f"   âœ“ å“åº”å¤§å°: {len(response.text):,} å­—ç¬¦\n")
        print("2. è§£æ HTML...")

    soup = BeautifulSoup(response.text, 'html.parser')
    token_rows = soup.select('a.ds-dex-table-row')

    if not token_rows:
        if verbose:
            print("   âŒ æœªæ‰¾åˆ°ä»£å¸è¡Œ")
        return []

    if verbose:
        print(f"   âœ“ æ‰¾åˆ° {len(token_rows)} ä¸ªä»£å¸è¡Œ\n")
        print("3. æå–ä»£å¸æ•°æ®...")

    tokens = []
    for i, row in enumerate(token_rows[:limit], 1):
        token_data = parse_token_row(row, i, chain)
        if token_data:
            tokens.append(token_data)

    if verbose:
        print(f"   âœ“ æˆåŠŸæå– {len(tokens)} ä¸ªä»£å¸\n")

    return tokens


def get_top_gainers(chain: str = 'bsc', top_n: int = 10) -> List[Dict[str, Any]]:
    """
    è·å–æŒ‡å®šé“¾çš„ Top N æ¶¨å¹…ä»£å¸

    Args:
        chain: bsc æˆ– solana
        top_n: å‰Nä¸ª

    Returns:
        æŒ‰24hæ¶¨å¹…æ’åºçš„ä»£å¸åˆ—è¡¨
    """
    tokens = scrape_dexscreener(chain=chain, limit=100, verbose=True)

    # è¿‡æ»¤æœ‰24hæ•°æ®çš„ä»£å¸
    tokens_with_24h = [t for t in tokens if 'price_change_24h' in t]

    # æŒ‰24hæ¶¨å¹…é™åºæ’åº
    top_tokens = sorted(tokens_with_24h, key=lambda x: x.get('price_change_24h', 0), reverse=True)[:top_n]

    return top_tokens


def find_specific_pair(chain: str, pair_address: str) -> Dict:
    """æŸ¥æ‰¾ç‰¹å®šçš„ pair"""
    tokens = scrape_dexscreener(chain=chain, limit=100, verbose=True)

    pair_address = pair_address.lower()
    for token in tokens:
        if token.get('pair_address', '').lower() == pair_address:
            return token

    return None


if __name__ == "__main__":
    print("\n" + "="*80)
    print("DexScreener çˆ¬è™« - æœ€ç»ˆç‰ˆæœ¬")
    print("="*80)

    # 1. çˆ¬å– BSC Top 10
    print("\nğŸ”¹ BSC é“¾")
    bsc_top10 = get_top_gainers(chain='bsc', top_n=10)

    print("="*80)
    print("BSC - Top 10 æ¶¨å¹…ä»£å¸")
    print("="*80)
    for i, token in enumerate(bsc_top10, 1):
        symbol = token.get('token_symbol', 'N/A')[:15]
        change_24h = token.get('price_change_24h', 0)
        price = token.get('price_usd', 0)
        mcap = token.get('market_cap', 0)

        print(f"{i:2d}. {symbol:15s} ${price:12.8f} 24h:{change_24h:+8.1f}% MCap:${mcap:12,.0f}")

    # ç­‰å¾…ä¸€ä¸‹ï¼Œé¿å…è¯·æ±‚å¤ªå¿«
    print("\nâ³ ç­‰å¾…5ç§’åè¯·æ±‚ Solana...")
    time.sleep(5)

    # 2. çˆ¬å– Solana Top 10
    print("\nğŸ”¹ Solana é“¾")
    solana_top10 = get_top_gainers(chain='solana', top_n=10)

    print("="*80)
    print("Solana - Top 10 æ¶¨å¹…ä»£å¸")
    print("="*80)
    for i, token in enumerate(solana_top10, 1):
        symbol = token.get('token_symbol', 'N/A')[:15]
        change_24h = token.get('price_change_24h', 0)
        price = token.get('price_usd', 0)
        mcap = token.get('market_cap', 0)

        print(f"{i:2d}. {symbol:15s} ${price:12.8f} 24h:{change_24h:+8.1f}% MCap:${mcap:12,.0f}")

    # 3. æŸ¥æ‰¾ç‰¹å®š BSC pair
    target_pair = '0xd504bcaebad45a1c92b14b14a9ab29a566ed2d42'

    print("\nâ³ ç­‰å¾…5ç§’åæŸ¥æ‰¾ç‰¹å®š pair...")
    time.sleep(5)

    print(f"\nğŸ”¹ æŸ¥æ‰¾ BSC Pair: {target_pair}")
    target_token = find_specific_pair('bsc', target_pair)

    if target_token:
        print("\n" + "="*80)
        print(f"æ‰¾åˆ° DRAGON ä»£å¸ (Pair: {target_pair})")
        print("="*80)
        print(f"\næ’å:        #{target_token.get('rank', 'N/A')}")
        print(f"ä»£å¸:        {target_token.get('token_symbol', 'N/A')}")
        print(f"ä»·æ ¼:        ${target_token.get('price_usd', 0):.8f}")
        print(f"5mæ¶¨å¹…:      {target_token.get('price_change_5m', 0):+.2f}%")
        print(f"1hæ¶¨å¹…:      {target_token.get('price_change_1h', 0):+.2f}%")
        print(f"6hæ¶¨å¹…:      {target_token.get('price_change_6h', 0):+.2f}%")
        print(f"24hæ¶¨å¹…:     {target_token.get('price_change_24h', 0):+.2f}%")
        print(f"å¸‚å€¼:        ${target_token.get('market_cap', 0):,.0f}")
        print(f"æµåŠ¨æ€§:      ${target_token.get('liquidity_usd', 0):,.0f}")
        print(f"é“¾æ¥:        {target_token.get('url', 'N/A')}")
    else:
        print("\nâŒ æœªæ‰¾åˆ°è¯¥ pair (å¯èƒ½ä¸åœ¨å‰100å)")

    # 4. ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    result = {
        'timestamp': timestamp,
        'bsc_top10': bsc_top10,
        'solana_top10': solana_top10,
        'target_pair': target_token if target_token else None,
    }

    output_file = f'dexscreener_result_{timestamp}.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)

    print("\n" + "="*80)
    print(f"âœ… å®Œæˆï¼æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
    print("="*80)
